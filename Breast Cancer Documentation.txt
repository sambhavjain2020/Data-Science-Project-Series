Breast Cancer Diagnosis Prediction - Project Documentation


1. Data Preprocessing:
   - Loaded the Breast Cancer Wisconsin (Diagnostic) dataset from the provided CSV file.
   - Checked for missing values and dropped any rows containing NaN values.
   - Separated the features (X) and the target variable (y), where 'Diagnosis' represents the target.
   - Applied one-hot encoding to categorical variables using pandas `get_dummies` method.

2. Feature Selection and Engineering:
   - Utilized ANOVA F-statistic for feature selection.
   - Selected the top 10 features based on the F-statistic scores.
   - Created a new DataFrame with only the selected features for further analysis.

3. Machine Learning Model (SVM):
   - Implemented a Support Vector Machine (SVM) model using scikit-learn.
   - Trained the model on the Breast Cancer dataset with the selected features.
   - Evaluated the model's performance using metrics such as accuracy, precision, recall, and F1-score.

4. Performance Metrics:
   - Accuracy: The percentage of correctly classified instances.
   - Precision: The ratio of true positive predictions to the total predicted positives.
   - Recall: The ratio of true positive predictions to the total actual positives.
   - F1-score: The harmonic mean of precision and recall, providing a balanced metric.

5. Challenges Faced:
   - Data Quality: Ensured that the dataset had minimal missing values and handled them appropriately.
   - Categorical Variables: Encoded categorical variables to ensure compatibility with the SVM model.
   - Model Tuning: Explored different SVM hyperparameters for optimal model performance.
   - Interpretability: Considered the interpretability of the SVM model and the significance of selected features.

6. Conclusion:
   - The SVM model demonstrates promising performance in predicting breast cancer diagnosis.
   - The selected features play a crucial role in the model's decision-making process.

7. Future Work:
   - Experiment with other machine learning algorithms for comparison.
   - Explore additional feature engineering techniques to enhance model performance.
   - Investigate potential interactions between features for a deeper understanding of the data.
